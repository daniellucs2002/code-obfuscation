{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  # simulate command line arguments\n",
    "\n",
    "sys.argv = ['client.py', \n",
    "            '--cuda', '2',\n",
    "            '--files', '1',\n",
    "            '--peek', '64',\n",
    "            '--versions', '3',\n",
    "            '--batch', '32',\n",
    "            '--masked', '0.2',\n",
    "            '--topk', '5'\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('max_colwidth',300)\n",
    "\n",
    "from datasets import Dataset\n",
    "from pathlib import Path\n",
    "from transformers import logging as transformers_logging\n",
    "from transformers import RobertaTokenizer, RobertaForMaskedLM, DataCollatorForLanguageModeling\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--cuda', type=int, default=0, help='CUDA ID (0-3)')\n",
    "parser.add_argument('--files', type=int, default=14, help='file numbers to be processed (1-14)')\n",
    "parser.add_argument('--peek', type=int, default=0, help='print out samples during developing phase')\n",
    "parser.add_argument('--versions', type=int, default=3, help='number of obfuscation versions in the comparison dataset')\n",
    "parser.add_argument('--batch', type=int, default=32, help='batch size for the client side model')\n",
    "parser.add_argument('--masked', type=float, default=0.1, help='probability to introduce <mask> token')\n",
    "parser.add_argument('--topk', type=int, default=5, help='use top_k sampling method')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{args.cuda}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# step 1: prepare the raw data (python)\n",
    "\n",
    "files = []\n",
    "for i in range(0, args.files):\n",
    "    files.extend(Path('./data/python/').glob(f'**/python_train_{i}.jsonl.gz'))\n",
    "\n",
    "codes = pd.concat([pd.read_json(f,\n",
    "                                orient='records',\n",
    "                                compression='gzip',\n",
    "                                lines=True)[['code_tokens']]\n",
    "                   for f in files], sort=False)\n",
    "codes['filtered_code_tokens'] = [[token for token in row if len(token) > 0 and token[0] != '#']\n",
    "                                for row in codes['code_tokens']]\n",
    "codes['code_string'] = [' '.join(row) for row in codes['filtered_code_tokens']]\n",
    "\n",
    "if args.peek != 0:\n",
    "    codes = codes.iloc[:args.peek]  # constrain to the first few batches\n",
    "hf_codes = Dataset.from_pandas(codes)\n",
    "\n",
    "transformers_logging.set_verbosity_error()\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
    "model = RobertaForMaskedLM.from_pretrained(\"microsoft/codebert-base-mlm\")\n",
    "transformers_logging.set_verbosity_warning()\n",
    "model.to(device)\n",
    "\n",
    "def tokenize_fn(example):\n",
    "    return tokenizer(\n",
    "        example['code_string'],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "hf_codes = hf_codes.map(\n",
    "    tokenize_fn,\n",
    "    batched=True,\n",
    "    num_proc=4,\n",
    "    remove_columns=['code_tokens', 'filtered_code_tokens']\n",
    ")  # 'code_string'(original), 'input_ids', 'attention_mask'\n",
    "\n",
    "# step 2: introduce <mask> token for comparison dataset\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=args.masked\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_multiple_obfuscated_versions(batch):\n",
    "    print(batch['code_string'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obfuscated_dataset = hf_codes.map(\n",
    "    generate_multiple_obfuscated_versions,\n",
    "    batched=True,\n",
    "    batch_size=args.batch\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daniel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
